<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Learning Monocular Dense Depth From Events | Siyuan Wu</title> <meta name="author" content="Siyuan Wu"> <meta name="description" content="1. Reproduced the research paper " learning monocular dense depth from events scratch> </head> <body> <p> 2. Trained the reproduced model on DSEC dataset <br> 3. Improved the performance by introducing SSIM loss <br> This is the course project of <b>Seminar Computer Vision by Deep Learning</b> at TU Delft." /&gt; <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="siyuanwu99.github.io/projects/cs4245/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </p> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Siyuan Wu</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Learning Monocular Dense Depth From Events</h1> </header> <article> <p>For futher details, you can check our github repository at <a href="https://github.com/siyuanwu99/DSEC" rel="external nofollow noopener" target="_blank">siyuanwu99/DSEC</a></p> <h2 id="network-structure">Network Structure</h2> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cvbydl_structure-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cvbydl_structure-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cvbydl_structure-1400.webp"></source> <img src="/assets/img/cvbydl_structure.png" class="img-fluid rounded z-depth-1" width="640" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>As shown in the figure above, the network we produced has a recurrent, fully convolutional structure. It can simply be divided as a header, an encoder, residual blocks, a decoder and a predictor.</p> <p>This network structure draws on UNet, which has proven its potential on Frame-based Depth Estimation tasks. The skip connections between encoder and decoder make sure features are learned for contracting the image can be used for reconstruction. Therefore, it guarantees the performance for pixel-by-pixel prediction. Due to the flow mechanism of event data, the input voxel grid shares some information with other grids, therefore, LSTM is used to discover temporal features.</p> <p>The header of this network is a 2D convolutional layer followed by Batch Normalization. The kernel size is set to be 5. The activation function is ReLU. It takes 15x640x480 event volumn as input. The encoder consists of three similar layers with different channel size. Each layer has a 2D convolutional layer and a ConvLSTM layer, which has a LSTM structure with a convolultional gate. The kernel size of convolutional layer is 5, and that of ConvLSTM is selected to be 3. After the encoder is 2 cascade residual layers with kernel size 3. In the residual layer there are 2 convolutional network with Batch Normalization. The activation function is ReLU. Summation is applied over the skip connection. The decoder has three similar layers with different output channel size. Each layer consists of an upsampling convolution and a normal convolution with kernel size 5. Finally, the network use a predictor to output, which is a depth-wise convolution with kernel size 1. This network applies summation over all the skip connections. States from the ConvLSTM will be used for the next event volumn.</p> <h2 id="results">Results</h2> <p>We trained our model on Tesla T4 GPU from Google Colab, with a memory of approximately 15 GB. We only finished <strong>50</strong> epoches training due to limited time and resources.</p> <p><em>Lower value indicates better result for all metrics.</em></p> <hr> <table> <thead> <tr> <th style="text-align: center">Metric</th> <th style="text-align: center">Total Mean absolute error(MAE)</th> <th style="text-align: center">Total Mean square error(MSE)</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Performance</td> <td style="text-align: center">16.84</td> <td style="text-align: center">380.07</td> </tr> </tbody> </table> <hr> <table> <thead> <tr> <th style="text-align: center">Model types</th> <th style="text-align: center">Event based</th> <th style="text-align: center">Event based</th> <th style="text-align: center">Frame based</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Metrics</td> <td style="text-align: center">Paper model[^7]</td> <td style="text-align: center">Our model</td> <td style="text-align: center">MonoDepth[^9]</td> </tr> <tr> <td style="text-align: center">MAE in 10m</td> <td style="text-align: center"><strong>1.85</strong></td> <td style="text-align: center">5.32</td> <td style="text-align: center">3.44</td> </tr> <tr> <td style="text-align: center">MAE in 20m</td> <td style="text-align: center"><strong>2.64</strong></td> <td style="text-align: center">8.94</td> <td style="text-align: center">7.02</td> </tr> <tr> <td style="text-align: center">MAE in 30m</td> <td style="text-align: center"><strong>3.13</strong></td> <td style="text-align: center">12.04</td> <td style="text-align: center">10.03</td> </tr> </tbody> </table> <hr> <p>In the paper, they trained <strong>300 epoches (127800 iterations)</strong> on the real world dataset consist of <strong>8523 samples</strong>. Due to limited computation resources, we trained <strong>50 epoches</strong> on a smaller dataset with <strong>225 samples</strong> only. Each sample is a 50ms time window consist of 5,000 to 500,000 events. Though produced reasonable results, our model still underperforms the baseline models.</p> <h3 id="results-with-ssim-loss">Results with SSIM Loss</h3> <p>We trained the model again with SSIM loss term. After only 7 epochs, we already observe lower metric errors. For comparison, we also overlay the orignal training metric curves without SSIM loss. The metric plots for the first 7 epochs are shown as follow. As you can see, the model with <strong>SSIM loss (dark blue)</strong> performs better than <strong>original model (light blue)</strong>, which Mean Average Error for all stages decreases more slowly. With SSIM loss term, the metric errors descend to low values after training for only 7 epochs.</p> <hr> <table> <thead> <tr> <th style="text-align: center">Model</th> <th style="text-align: center">MAE</th> <th style="text-align: center">MSE</th> <th style="text-align: center">MAE in 10m</th> <th style="text-align: center">MAE in 20m</th> <th style="text-align: center">MAE in 30m</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Model trained with SSIM loss</td> <td style="text-align: center"><strong>13.84</strong></td> <td style="text-align: center"><strong>339.28</strong></td> <td style="text-align: center"><strong>3.22</strong></td> <td style="text-align: center"><strong>4.83</strong></td> <td style="text-align: center"><strong>7.85</strong></td> </tr> <tr> <td style="text-align: center">Original model</td> <td style="text-align: center">20.43</td> <td style="text-align: center">616.21</td> <td style="text-align: center">5.08</td> <td style="text-align: center">9.09</td> <td style="text-align: center">13.43</td> </tr> </tbody> </table> <hr> <p>Due to time limit, we did not train the model with SSIM loss again for 50 epochs. But the model metrics are already better than the previous results. This implies the SSIM loss could not only be used for training on image data from frame-based camera, but also be applied to event data.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Siyuan Wu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: April 04, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://cdn.panelbear.com/analytics.js?site=141v6hERZVq"></script> <script>window.panelbear=window.panelbear||function(){(window.panelbear.q=window.panelbear.q||[]).push(arguments)},panelbear("config",{site:"141v6hERZVq"});</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>