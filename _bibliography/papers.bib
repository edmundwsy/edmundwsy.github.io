---
---

@string{auro = {Auton. Robots}}
@string{icra = {Proc. of the {IEEE} Intl. Conf. on Robot. and Autom. (ICRA)}}
@string{dars = {Intl. Sym. on Distributed Auton. Syst.}}
@string{ram = {{IEEE} Robot. Autom. Mag. (RA-M)}}
@string{ral = {{IEEE} Robot. Autom. Lett. (RA-L)}}
@string{iser = {Proc. of the Intl. Sym. on Exp. Robot.}}
@string{isrr = {Proc. of the Intl. Sym. of Robot. Research}}
@string{iros = {Proc. of the {IEEE/RSJ} Intl. Conf. on Intell. Robots and Syst. (IROS)}}
@string{ecmr = {Proc. of the Euro. Conf. on Mobile Robot.}}
@string{proc = {Proc. of the {IEEE}}}
@string{ijrr = {Intl. J. Robot. Research (IJRR)}}
@string{ijcv = {Intl. J. Comput. Vis.}}
@string{jfr = {J. Field Robot.}}
@string{tor = {{IEEE} Trans. Robot.}}
@string{rss = {Proc. of Robot.: Sci. and Syst. (RSS) }}
@string{cvpr = {Proc. of the {IEEE} Intl. Conf. on Pattern Recognition (CVPR) }}
@string{cdc = {Proc. of the {IEEE} Control and Decision Conf.}}
@string{icuas = {Proc. of the Intl. Conf. on Unma. Air. Syst.}}
@string{caes = {Proc. of the Conf. on Ann. Euro. Sym.}}

@article{DBLP:journals/corr/abs-2103-05903,
  author    = {Botao He and
               Haojia Li and
               Siyuan Wu and
               Dong Wang and
               Zhiwei Zhang and
               Qianli Dong and
               Chao Xu and
               Fei Gao},
  title     = {FAST-Dynamic-Vision: Detection and Tracking Dynamic Objects with Event
               and Depth Sensing},
  abbr      = {IROS},
  journal   = {IROS},
  pdf       = {IROS2021.pdf},
  year      = {2021},
  arxiv     = {2103.05903},
  code      = {https://github.com/ZJU-FAST-Lab/FAST-Dynamic-Vision},
  video     = {https://www.youtube.com/watch?v=QPpwppeE_x0&ab_channel=FeiGao},
  selected  = {true},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-05903.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract  = {The development of aerial autonomy has enabled aerial robots to fly agilely in complex environments. However, dodging fast-moving objects in flight remains a challenge, limiting the further application of unmanned aerial vehicles (UAVs). The bottleneck of solving this problem is the accurate perception of rapid dynamic objects. Recently, event cameras have shown great potential in solving this problem. This paper presents a complete perception system including ego-motion compensation, object detection, and trajectory prediction for fast-moving dynamic objects with low latency and high precision. Firstly, we propose an accurate ego-motion compensation algorithm by considering both rotational and translational motion for more robust object detection. Then, for dynamic object detection, an event camera-based efficient regression algorithm is designed. Finally, we propose an optimizationbased approach that asynchronously fuses event and depth cameras for trajectory prediction. Extensive real-world experiments and benchmarks are performed to validate our framework. Moreover, our code will be released to benefit related researches.}
}

